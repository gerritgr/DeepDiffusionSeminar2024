{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Graphically Structured Diffusion Models\n",
        "\n",
        "\n",
        "\n",
        "Notebook's author: Yasin Esfandiari\n",
        "\n",
        "Paper: Graphically Structured Diffusion Models [[link](https://https://arxiv.org/abs/2210.11633)]\n",
        "\n",
        "Slides: Presented in the seminar [[link](https://docs.google.com/presentation/d/1j5lyHV5XE9ayyHj9vWjaL5Bw6aKu3cQZ/view)]"
      ],
      "metadata": {
        "id": "Zz6abVQ_Vho-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://raw.githubusercontent.com/yasin-esfandiari/deepdiffusion_seminar/main/assets/paper_info.png' width=110% />"
      ],
      "metadata": {
        "id": "6LVHefTFMEW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction"
      ],
      "metadata": {
        "id": "VK5U9U2XVtD4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3vSJnhXpc0z"
      },
      "source": [
        "In this tutorial, we will take a deeper look into the **Graphically Structured Diffusion Models**. It is assumed that you are already familiar with the basic concepts of Diffusion Models. The paper tackled four different (inverse) problems as follows:\n",
        "\n",
        "1.   Binary Continuous Matrix Factorization\n",
        "2.   Sudoku\n",
        "3.   Array Logical Gate classifier\n",
        "4.   Sorting\n",
        "\n",
        "For simplicity and better conveying the important notes, we will focus on the Sorting problem. Please note that for a better reading, the large classes have been divided into multiple blocks (using inheritance) so that some descriptions can be added."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://raw.githubusercontent.com/yasin-esfandiari/deepdiffusion_seminar/main/assets/sorting_problem.png' />"
      ],
      "metadata": {
        "id": "gUWULJ5UxV6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "(1) Sample an unsorted list $u ∈ R^n$. with each element $u_i$\n",
        "sampled from a unit normal.\n",
        "\n",
        "(2) Sample a permutation matrix $P ∈ \\{0, 1\\}^{n×n}$. Factors on each row and column enforce that there should be a single 1 in each.\n",
        "\n",
        "(3) Multiply $P$ and $u$. We integrate intermediate variables $C_{ij} := P_{ij}u_j$ and sum them as $s_i := \\sum_{j} ^{} C_{ij}$ to yield $s = Pu$.\n",
        "\n",
        "(4) We use factors between each pair of elements in $s$ to enforce that it is sorted.\n",
        "\n",
        "We measure its performance as the RMSE between the ground-truth $s$ and the observed $u$ transformed by the sampled $P$, and plot progress during training. For these check the `validation_metrics` and the video created using `plot` later."
      ],
      "metadata": {
        "id": "6PXASXa22X2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The $u$ and $s$, as well as the intermediate variables, if exist, are continuous, while $P$ is discrete. So before feeding to the network we dequantize $P$ to be contunous. For sampling, we quantize it to make it discrete."
      ],
      "metadata": {
        "id": "QtDmG8_b3d4s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkEuDrG1qF8H"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Packages\n",
        " Installing the required packages (silent mode)"
      ],
      "metadata": {
        "id": "X12KreuVV2tm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "keI4Qm905syQ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "!{sys.executable} -m pip install torch torchaudio torchvision certifi charset-normalizer click cycler docker-pycreds fonttools gitdb GitPython idna kiwisolver matplotlib numpy packaging pathtools \\\n",
        "Pillow promise protobuf psutil pyparsing python-dateutil PyYAML requests scipy sentry-sdk setproctitle shortuuid six smmap sudoku-solver tqdm urllib3 wandb jupyter_contrib_nbextensions --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Retrieving the checkpoints and data"
      ],
      "metadata": {
        "id": "1sHrGPYlBZGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yasin-esfandiari/deepdiffusion_seminar"
      ],
      "metadata": {
        "id": "bbURotOSBgqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCVW5CtYiVFM"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import traceback\n",
        "import shutil\n",
        "import logging\n",
        "import yaml\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import wandb\n",
        "\n",
        "import time\n",
        "import glob\n",
        "import itertools\n",
        "\n",
        "import tqdm\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.utils as tvu\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from numpy.random import randint\n",
        "import functools\n",
        "import random\n",
        "import torch as th\n",
        "import os.path\n",
        "import hashlib\n",
        "import errno\n",
        "from torch.utils.model_zoo import tqdm\n",
        "\n",
        "import numbers\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import logging\n",
        "import glob\n",
        "\n",
        "import torch.nn.functional as TF\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "Bz0PhjkLYGAq"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fix encodings issues in Colab"
      ],
      "metadata": {
        "id": "O6Z0gOLp9kaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "torch.set_printoptions(sci_mode=False)  ## Disable scientific notation"
      ],
      "metadata": {
        "id": "dz1IT6Wk9qs1"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L2tfauHsbBY"
      },
      "source": [
        "## Insert your wandb credentials\n",
        "\n",
        "Create a project in you wandb account with the name 'GSDM'. Add the entity and the API Key below. The entity is your account name. Please follow the [Quickstart](https://wandb.ai/quickstart?utm_source=app-resource-center&utm_medium=app&utm_term=quickstart)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdg3qQImiqQy",
        "outputId": "2889f0ab-3e35-4360-a26b-4a71cf936620"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "auth_token = ''\n",
        "entity = ''\n",
        "project = 'GSDM'\n",
        "\n",
        "os.system(f'wandb login {auth_token}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parameters"
      ],
      "metadata": {
        "id": "mhcQDoCMYaD9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAhZI-6mkXNp"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "First, we define a dictionary of type configurables and we use it later to set the configurations. These involve the configurations for the Model, Training, Optimization, Diffusion, and Sampling."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str2bool = lambda s: 't' in s.lower()\n",
        "configurable = {'model': {'resnet': str2bool,\n",
        "                          'num_transformers': int,\n",
        "                          'emb_dim': int,\n",
        "                          'predict': str,\n",
        "                          'softmax': str2bool,\n",
        "                          'var_embedding': str2bool,\n",
        "                          'n_heads': int,\n",
        "                          'attn_dim_reduce': int,\n",
        "                          'impose_sparsity': str,\n",
        "                          'max_attn_matrix_size': int,\n",
        "                          'ema': str2bool,},\n",
        "                'training': {'n_epochs': int,\n",
        "                              'batch_size': int,\n",
        "                              'max_epoch_iters': int,\n",
        "                              'attn_reg_iters': int,\n",
        "                              'validation_freq': int,\n",
        "                              \"mean_latents_loss\": str2bool},\n",
        "                'optim': {'lr': float},\n",
        "                'data': {'n_discrete_options': eval,\n",
        "                          'type': int,\n",
        "                          'n': int,\n",
        "                          'fit_intermediate': str2bool,\n",
        "                          'save_sparsity_mask': str2bool,\n",
        "                          'sparsity_mask_index': int,\n",
        "                          'supervise_intermediate': str2bool,\n",
        "                          'dataset_length': int,\n",
        "                          'num_workers': int,\n",
        "                          },\n",
        "                'diffusion': {'beta_schedule': str,\n",
        "                              'beta_start': float,\n",
        "                              'beta_end': float,\n",
        "                              'num_diffusion_timesteps': int},\n",
        "                'sampling': {'sampling_batch_size': int}\n",
        "                }"
      ],
      "metadata": {
        "id": "e89sDo_4stqt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "JIos117jkVGv"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "  'data': {\n",
        "    'dataset': \"Sorting\",\n",
        "    'num_workers': 0,\n",
        "    'dataset_length': 1000,\n",
        "    'test_dataset_length': 100,\n",
        "    'save_sparsity_mask': False,  # save the mask as .npz file\n",
        "    'fit_intermediate': True,  # whether to consider extra intermediate variables\n",
        "    'sparsity_mask_index': 2, # connection in the graphical model\n",
        "  },\n",
        "  'model': {\n",
        "      'emb_dim': 64,\n",
        "      'num_transformers': 6,\n",
        "      'var_type': 'fixedlarge',\n",
        "      'ema_rate': 0.5,\n",
        "      'ema': True,\n",
        "      'predict': 'x0',            # predict x0 or eps\n",
        "      'softmax': True,\n",
        "      'var_embedding': True,\n",
        "      'resnet': True,\n",
        "      'n_heads': 1, # number of transformer heads\n",
        "      'attn_dim_reduce': 1,\n",
        "      'impose_sparsity': 'sparse',  ## [sparse, not]\n",
        "  },\n",
        "  'diffusion': {\n",
        "      'beta_schedule': 'linear',\n",
        "      'beta_start': 0.0001,\n",
        "      'beta_end': 0.005,\n",
        "      'num_diffusion_timesteps': 1000,  # this is for training\n",
        "  },\n",
        "  'training': {\n",
        "      'batch_size': 10,\n",
        "      'n_epochs': 150,\n",
        "      'max_epoch_iters': 1000,\n",
        "      'snapshot_freq': 20000,\n",
        "      'mean_latents_loss': False,\n",
        "  },\n",
        "  'sampling': {\n",
        "      'sampling_batch_size': 4,\n",
        "  },\n",
        "  'optim': {\n",
        "      'weight_decay': 0.000,\n",
        "      'optimizer': \"Adam\",\n",
        "      'lr': 0.0002,\n",
        "      'beta1': 0.9,\n",
        "      'amsgrad': False,\n",
        "      'eps': 0.00000001,\n",
        "      'grad_clip': 1.0,\n",
        "\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G_bH0ZInz3V"
      },
      "source": [
        "##Arguments\n",
        "\n",
        "Here we set the arguments. For training for the beginning, Set the 'eval_path' as None, and for loading the checkpoints, set the value to the checkpoint's path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "D6lSdgi0pV7e"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "  'exp': 'sorting_experiments',                                       # Path for saving running related data.\n",
        "  'verbose': 'critical',                                              # Verbose level: info | debug | warning | critical\n",
        "  # 'eval_path': None,                                                # If None, do training.\n",
        "  # 'eval_path': 'sorting_experiments/logs/gsdm_code/ckpt.pth',       # If specified, evaluate this ckpt instead of training. (use after re-train)\n",
        "  'eval_path': 'deepdiffusion_seminar/checkpoints/ckpt.pth',          # If specified, evaluate this ckpt instead of training. (use from the git repo)\n",
        "  'wandb_tags': '',                                                   # Tags for wandb\n",
        "  'resume_id': 'gsdm_code',                                           # your job name\n",
        "  'sample_type': 'ddpm',                                              # sampling approach (ddpm)\n",
        "  'skip_type': 'uniform',                                             # skip according to (uniform or quadratic)\n",
        "  'timesteps': 1000,                                                  # number of steps involved in sampling\n",
        "  'weight_loss': True,                                                # Apply weights to the MSE loss so that it is equivalent to the ELBO\n",
        "  'log_freq': 10000,                                                  # How often to log training progress\n",
        "\n",
        "  'n_epochs': 60,                                                     # GSDM w/ IE\n",
        "  'n': 10,                                                            # size of the unsorted vector u in our sorting problem\n",
        "  'batch_size': 16,\n",
        "  'sampling_batch_size': 16,\n",
        "  'max_epoch_iters': 1000,\n",
        "  'seed': 0                                                           # for reproducibility\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us set the device to cuda if a GPU is available, otherwise to CPU."
      ],
      "metadata": {
        "id": "43v1MEXCDzdz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "OsL84k58mR9Q"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "logging.info(\"Using device: {}\".format(device))\n",
        "config['device'] = device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTc9VNfYYsk"
      },
      "source": [
        "Let us set the configuration as a namespace. We set the values based on the args dictionary that we defined previously. In the namespace, we can access the local elements using dot notation. You can see the config as both dictionary and namespace in the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuDWuyV1XnGQ",
        "outputId": "44df5f29-e7f3-45a8-cdbe-f15035ac759a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config as dictionary: {'data': {'dataset': 'Sorting', 'num_workers': 0, 'dataset_length': 1000, 'test_dataset_length': 100, 'save_sparsity_mask': False, 'fit_intermediate': True, 'sparsity_mask_index': 2}, 'model': {'emb_dim': 64, 'num_transformers': 6, 'var_type': 'fixedlarge', 'ema_rate': 0.5, 'ema': True, 'predict': 'x0', 'softmax': True, 'var_embedding': True, 'resnet': True, 'n_heads': 1, 'attn_dim_reduce': 1, 'impose_sparsity': 'sparse'}, 'diffusion': {'beta_schedule': 'linear', 'beta_start': 0.0001, 'beta_end': 0.005, 'num_diffusion_timesteps': 1000}, 'training': {'batch_size': 10, 'n_epochs': 150, 'max_epoch_iters': 1000, 'snapshot_freq': 20000, 'mean_latents_loss': False}, 'sampling': {'sampling_batch_size': 4}, 'optim': {'weight_decay': 0.0, 'optimizer': 'Adam', 'lr': 0.0002, 'beta1': 0.9, 'amsgrad': False, 'eps': 1e-08, 'grad_clip': 1.0}, 'device': device(type='cuda')}\n",
            "config as namespace: Namespace(data=Namespace(dataset='Sorting', num_workers=0, dataset_length=1000, test_dataset_length=100, save_sparsity_mask=False, fit_intermediate=True, sparsity_mask_index=2, n=10), model=Namespace(emb_dim=64, num_transformers=6, var_type='fixedlarge', ema_rate=0.5, ema=True, predict='x0', softmax=True, var_embedding=True, resnet=True, n_heads=1, attn_dim_reduce=1, impose_sparsity='sparse'), diffusion=Namespace(beta_schedule='linear', beta_start=0.0001, beta_end=0.005, num_diffusion_timesteps=1000), training=Namespace(batch_size=16, n_epochs=60, max_epoch_iters=1000, snapshot_freq=20000, mean_latents_loss=False), sampling=Namespace(sampling_batch_size=16), optim=Namespace(weight_decay=0.0, optimizer='Adam', lr=0.0002, beta1=0.9, amsgrad=False, eps=1e-08, grad_clip=1.0), device=device(type='cuda'))\n"
          ]
        }
      ],
      "source": [
        "def dict2namespace(config):\n",
        "    namespace = argparse.Namespace()\n",
        "    for key, value in config.items():\n",
        "        if isinstance(value, dict):\n",
        "            new_value = dict2namespace(value)\n",
        "        else:\n",
        "            new_value = value\n",
        "        setattr(namespace, key, new_value)\n",
        "    return namespace\n",
        "\n",
        "\n",
        "\n",
        "print(f\"config as dictionary: {config}\")\n",
        "for arg_type, type_configurable in configurable.items():\n",
        "    for arg in type_configurable:\n",
        "        try:\n",
        "            config[arg_type][arg] = args[arg]\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "config = dict2namespace(config)\n",
        "print(f\"config as namespace: {config}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_SWW0IKPZqO",
        "outputId": "0a089b43-0f14-4d52-d8a4-5dc7f3e8615b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(exp='sorting_experiments', verbose='critical', eval_path='deepdiffusion_seminar/checkpoints/ckpt.pth', wandb_tags='', resume_id='gsdm_codessz2', sample_type='ddpm', skip_type='uniform', timesteps=1000, weight_loss=True, log_freq=10000, n_epochs=60, n=10, batch_size=16, sampling_batch_size=16, max_epoch_iters=1000, seed=0)\n"
          ]
        }
      ],
      "source": [
        "args = dict2namespace(args)\n",
        "print(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set a seed for reproducibility"
      ],
      "metadata": {
        "id": "bZjgkBS3ECDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "4jRYiOsU4LdI"
      },
      "outputs": [],
      "source": [
        "# set random seed\n",
        "torch.manual_seed(args.seed)\n",
        "np.random.seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "616JJNXZV7ws"
      },
      "source": [
        "## Initialize WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcoe00odV_C6"
      },
      "outputs": [],
      "source": [
        "# initialise wandb ----------------------------------\n",
        "unpacked_config = {}\n",
        "for k, v in config.__dict__.items():\n",
        "    if isinstance(v, argparse.Namespace):\n",
        "        inner_dict = {k+'.'+k2: v2 for k2, v2 in v.__dict__.items()}\n",
        "        unpacked_config = {**unpacked_config, **inner_dict}\n",
        "    else:\n",
        "        unpacked_config[k] = v\n",
        "\n",
        "unpacked_args = {}\n",
        "for k, v in args.__dict__.items():\n",
        "    if isinstance(v, argparse.Namespace):\n",
        "        inner_dict = {k+'.'+k2: v2 for k2, v2 in v.__dict__.items()}\n",
        "        unpacked_args = {**unpacked_args, **inner_dict}\n",
        "    else:\n",
        "        unpacked_args[k] = v\n",
        "\n",
        "\n",
        "wandb.init(entity=entity, project=project,\n",
        "            config={**unpacked_config, **unpacked_args}, id=args.resume_id, tags=args.wandb_tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfhpjdNw_cCu"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sorting Dataset"
      ],
      "metadata": {
        "id": "3t94tjnraGpj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2hayx11ADp1"
      },
      "source": [
        "###Graphical dataset\n",
        "Let's create a generic graphical dataset. This includes fit_intermediate (whether we want to use intermediate variables). Let's impose the following structure on our dataset:\n",
        "\n",
        "\n",
        "*   $u$ is an unsorted vector of $n$ continuous elements\n",
        "*   $s$ is the sorted version of vector $u$\n",
        "*   $P$ is a $nxn$ binary matrix with only one element of 1 in each row/column\n",
        "*   $C$ is a $nxn$ continuous matrix to store the intermediate variables ($K$ in the code). For example, $C_{ij} := P_{ij}u_j$.\n",
        "\n",
        "The image below is from the main paper when the size of vector 𝑢 is 5. This will be our attention mask. To get this structure, we use `sorting_faithful_inversion_edges` function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://raw.githubusercontent.com/yasin-esfandiari/deepdiffusion_seminar/main/assets/attn_mask.png' width=60% />"
      ],
      "metadata": {
        "id": "KWISCuRwYHsi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "xvg0ndsTAFgG"
      },
      "outputs": [],
      "source": [
        "class GraphicalDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A dataset combined with a graphical model.\n",
        "    \"\"\"\n",
        "    def __init__(self, config, is_test):\n",
        "        super(Dataset, self).__init__()\n",
        "        self.config = config\n",
        "        self.length = config.data.test_dataset_length if is_test else config.data.dataset_length\n",
        "        self.is_test = is_test\n",
        "        self.fit_intermediate = self.config.data.fit_intermediate\n",
        "\n",
        "    def avg_log_prob(self, N=None):\n",
        "        return torch.tensor(0.0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def plot(self, samples_cont, samples_disc, obs_mask, **kwargs):\n",
        "        return None, None # fig, ax\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "wJOOY7dC_fZ5"
      },
      "outputs": [],
      "source": [
        "@functools.lru_cache(maxsize=1000, typed=False)\n",
        "def sorting_faithful_inversion_edges(n, nc, fit_intermediate, sparsity_mask_index):\n",
        "    \"\"\"\n",
        "    sparsity_mask_index:\n",
        "        - 0 for connecting to above and below\n",
        "        - 1 for connecting to everything\n",
        "        - 2 for connecting to nothing\n",
        "        - 3 for random\n",
        "        - 4 for not symmetrizing\n",
        "    \"\"\"\n",
        "\n",
        "    ## for the attention matrix, we need to find the correct indices to have [u, s, C/K, P] format...\n",
        "    s = lambda i: i + n\n",
        "    u = lambda i: i\n",
        "    P = lambda i, j: nc + i*n + j\n",
        "    K = lambda i, j: 2*n + i*n + j\n",
        "\n",
        "    ## random connection and return\n",
        "    if sparsity_mask_index == 3:\n",
        "        n_rows = 2*n + (1 + fit_intermediate) * n**2\n",
        "        edges = []\n",
        "        for r in range(n_rows):\n",
        "            edges.extend([(r, c) for c in np.random.choice(n_rows, n//2, replace=False)])\n",
        "        # symmetrize\n",
        "        edges += [(a, b) for (b, a) in edges]\n",
        "        return  set(edges)\n",
        "\n",
        "    edges = []\n",
        "    # connect all sorted elements\n",
        "    condition = {\n",
        "        0: (lambda i, j: (i == j + 1 or i == j - 1 or i == j)),\n",
        "        1: (lambda i, j: True),\n",
        "        2: (lambda i, j: (i == j)),\n",
        "        4: (lambda i, j: (i == j + 1 or i == j - 1 or i == j))\n",
        "    }[sparsity_mask_index]\n",
        "\n",
        "    edges += [(s(i), s(j))\n",
        "              for i in range(n)\n",
        "              for j in range(n)\n",
        "              if condition(i, j)]\n",
        "    # connect all unsorted elements to themselves\n",
        "    edges += [(u(i), u(i))\n",
        "              for i in range(n)]\n",
        "    # connect all rows/columns in P\n",
        "    edges += [(P(i, j), P(i, k)) for i in range(n) for j in range(n) for k in range(n)]\n",
        "    edges += [(P(i, j), P(k, j)) for i in range(n) for j in range(n) for k in range(n)]\n",
        "\n",
        "    if fit_intermediate:\n",
        "        # connect each element of u to column of K\n",
        "        edges += [(u(i), K(j, i)) for i in range(n) for j in range(n)]\n",
        "        # and each element of s to column of K\n",
        "        edges += [(K(i, j), s(i)) for i in range(n) for j in range(n)]\n",
        "        # connect each element in K to the respective element in P\n",
        "        edges += [(P(i, j), K(i, j)) for i in range(n) for j in range(n)]\n",
        "    else:\n",
        "        # and each element of s to column of P\n",
        "        edges += [(P(i, j), s(i)) for i in range(n) for j in range(n)]\n",
        "        # and connect all of u to all of s\n",
        "        edges += [(u(i), s(j)) for i in range(n) for j in range(n)]\n",
        "\n",
        "    # symmetrize\n",
        "    if sparsity_mask_index == 4:  # not adding the symeyric\n",
        "        edges = [(a, b) for (b, a) in edges]\n",
        "    else:\n",
        "        edges += [(a, b) for (b, a) in edges]\n",
        "    return  set(edges)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define our Sorting class inherited form the Graphical Dataset:\n"
      ],
      "metadata": {
        "id": "MTfH1vi6h9u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sorting(GraphicalDataset):\n",
        "\n",
        "    def __init__(self, config, is_test):\n",
        "        super().__init__(config, is_test)\n",
        "        self.n = self.config.data.n\n",
        "        self.fit_intermediate = self.config.data.fit_intermediate\n",
        "\n",
        "    @property\n",
        "    def n_cont(self): ## continuous variables u, s --> s is the same size as u (it is sorted)\n",
        "        n = self.n    ## 10\n",
        "        return n*2 + (n**2 if self.fit_intermediate else 0)   ## 20 + [100 bc intermediate C/K has n^2 elements]\n",
        "\n",
        "    @property\n",
        "    def shared_var_embeds(self):\n",
        "        n = self.n\n",
        "        return [n+0]*n + list(range(n)) + ([n+1]*(n**2) if self.fit_intermediate else []) + [n+2 if self.fit_intermediate else n+1]*(n**2)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "          return self.__unseeded_getitem__(index)\n",
        "\n",
        "    def __unseeded_getitem__(self, index):\n",
        "        n = self.n                  ## [10]\n",
        "        u = torch.randn(n)          ## [10]\n",
        "        u_sort = torch.sort(u)\n",
        "        P = torch.zeros(n, n)\n",
        "        K = torch.zeros(n, n) if self.fit_intermediate else torch.tensor([])\n",
        "        for (i, j) in enumerate(u_sort.indices):\n",
        "            P[i, j] = 1\n",
        "            if self.fit_intermediate:\n",
        "                K[i, j] = u[j]\n",
        "\n",
        "        cont = torch.cat([u, u_sort.values, K.flatten()], dim=0)    ## continuous variables\n",
        "        disc = P.flatten().long()                                   ## discrete variables\n",
        "\n",
        "        return cont, disc, (self.n_cont, self.n_discrete_options, self.shared_var_embeds), (self.n, )  ## for disc, cont refer to 3.5\n",
        "\n",
        "    @property\n",
        "    def n_discrete_options(self): ## P is the discrete one: n^2 options\n",
        "        n = self.n\n",
        "        return [2]*(n**2)\n",
        "\n",
        "    def faithful_inversion_edges(self):\n",
        "        return sorting_faithful_inversion_edges(n=int(self.n), nc=int(self.n_cont), fit_intermediate=bool(self.fit_intermediate),\n",
        "                                                sparsity_mask_index=self.config.data.sparsity_mask_index)\n",
        "\n",
        "\n",
        "    def sample_obs_mask(self, B, device):\n",
        "        \"\"\"\n",
        "        set the embedding to 1 only for the unsorted vector, because it is observed and we do not want to generate values for it\n",
        "        \"\"\"\n",
        "        n = self.n                                                                                     ## 10\n",
        "\n",
        "        cont_dim = self.n_cont                                                                         ## 20\n",
        "        emb = torch.zeros((B, cont_dim+n**2, 1), device=device)                                        ## [B, 120, 1]\n",
        "        emb[:, :n] = 1. # unsorted part: u section\n",
        "        xt = torch.cat([emb[:, :cont_dim, 0], emb[:, cont_dim:, 0], emb[:, cont_dim:, 0]], dim=1)      ## [B, 220] --> cont, cont, disc\n",
        "        return {\"emb\": emb, \"xt\": xt}"
      ],
      "metadata": {
        "id": "62M4p3j3iFVJ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extra functions for the dataset"
      ],
      "metadata": {
        "id": "SYxs5AjtaPaz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following two functions will be used during validation later.\n",
        "\n",
        "In `validation_metrics` function we have the discrete samples matrix $P$. The continuous samples vector contains the rest of the variables and we recover the unsorted vector $u$ from it. We find the ground-truth sorted version of vector $u$ and log the following values:\n",
        "\n",
        "1.   *sort_matches*: average number of matching indices in [0, 1]\n",
        "2.   *sort_completed*: total number of matching indices\n",
        "3.   *rmse*: Root-mean-square deviation between the approximated sorted and ground-truth sorted vector\n",
        "\n",
        "\n",
        "In the `plot` , we plot three subplots as follows:\n",
        "\n",
        "1.   Ground-truth sorted vector\n",
        "2.   Approximated sorted vector (by multiplying $P$ with $u$)\n",
        "3.   Mis-matches between the two previous vectors\n",
        "\n",
        "\n",
        "You can see an example of the plot below that happens during training.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4R3dvrAegJSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sorting(Sorting):\n",
        "    def validation_metrics(self, samples_disc, samples_cont, **kwargs):\n",
        "        \"\"\"\n",
        "        used during sampling method.\n",
        "        \"\"\"\n",
        "        B, n2 = samples_cont.shape\n",
        "        n = self.n\n",
        "        nc = self.n_cont\n",
        "        u = samples_cont[:, :n]\n",
        "        ground = torch.sort(u)\n",
        "        P = samples_disc.reshape(B, n, n)\n",
        "        approx = torch.argmax(P, dim=2)\n",
        "        sort_matches = (ground.indices == approx).sum()/(self.n*B)\n",
        "        ddpm_sort = torch.gather(u, 1, approx)\n",
        "        return {'sort_matches': sort_matches,\n",
        "           'sort_completed': (ground.indices == approx).all().item(),\n",
        "           'rmse': ((ground.values - ddpm_sort)**2).mean().sqrt()}      ## use the sampled P to find ddpm_sort\n",
        "\n",
        "    def plot(self, samples_cont, samples_disc, obs_mask):\n",
        "        B = len(samples_cont)\n",
        "        n = self.n\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=1)\n",
        "        x_cont = samples_cont[0]\n",
        "        x_disc = samples_disc[0]\n",
        "        u_sort = torch.sort(x_cont[:n])\n",
        "        axes[0].set_title(\"Sorted (ground truth)\")\n",
        "        axes[0].imshow(u_sort.values.reshape(1, -1), vmin=-3.0, vmax=3.0, cmap='gray')\n",
        "        P_ = x_disc.reshape(n, n).float()\n",
        "        x_sort = P_ @ x_cont[:n]\n",
        "        axes[1].set_title(\"Sorting process\")\n",
        "        axes[1].imshow(x_sort.reshape(1, -1), vmin=-3.0, vmax=3.0,\n",
        "                       cmap='gray')\n",
        "        axes[2].set_title(\"\")\n",
        "        axes[2].imshow((x_sort != u_sort.values).reshape(1, -1), vmin=0.0, vmax=5.0,\n",
        "                       cmap='hot')\n",
        "\n",
        "        for ax in np.array(axes).flatten():\n",
        "            ax.xaxis.set_visible(False)\n",
        "            plt.setp(ax.spines.values(), visible=False)\n",
        "            ax.tick_params(left=False, labelleft=False)\n",
        "            ax.patch.set_visible(False)\n",
        "        return fig, axes[0]\n"
      ],
      "metadata": {
        "id": "zuYnFPLIf0km"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyJusjno_gA9"
      },
      "source": [
        "For both training and evaluation, we need to get the data. The following `get_dataset` function returns the training and test data which have different lenghts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "TuqmQ7GZ_e3j"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def get_dataset(args, config):\n",
        "    if config.data.dataset == 'Sorting':\n",
        "        dataset = Sorting(config, is_test=False)\n",
        "        test_dataset = Sorting(config, is_test=True)\n",
        "    else:\n",
        "        raise Exception\n",
        "    return dataset, test_dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualisation of the training process"
      ],
      "metadata": {
        "id": "5OyDFIoia7ZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Code below loads a video of what happens during training. Basically, it is a stack of multiple plots together."
      ],
      "metadata": {
        "id": "Z0pWq4Fqpelv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## code : https://stackoverflow.com/questions/57377185/how-play-mp4-video-in-google-colab/69990457#69990457\n",
        "## video : https://plai.cs.ubc.ca/2022/11/16/graphically-structured-diffusion-models/\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def show_video(video_path, video_width = 600):\n",
        "\n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        "\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n",
        "\n",
        "show_video(\"./deepdiffusion_seminar/assets/sorting.mp4\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "vocsDPkWQkj_",
        "outputId": "0e6eb3b3-1538-44d6-88f1-b9fd3ffdcddb"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=600 controls><source src=\"data:video/mp4;base64,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\"></video>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3s7MsYAVhy0"
      },
      "source": [
        "#Diffusion Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEQNlEKp82R4"
      },
      "source": [
        "##Helper functions\n",
        "\n",
        "Here we define some helper functions. In the first one, get_timestep_embedding, we get the embeddings of timesteps. We also have an activation function and a group normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "RW3wmpGH8HPD"
      },
      "outputs": [],
      "source": [
        "def get_timestep_embedding(timesteps, embedding_dim, max_timesteps=10000):\n",
        "    \"\"\"\n",
        "    This matches the implementation in Denoising Diffusion Probabilistic Models:\n",
        "    From Fairseq.\n",
        "    Build sinusoidal embeddings.\n",
        "    This matches the implementation in tensor2tensor, but differs slightly\n",
        "    from the description in Section 3.5 of \"Attention Is All You Need\".\n",
        "    \"\"\"\n",
        "    assert len(timesteps.shape) == 1\n",
        "\n",
        "    half_dim = embedding_dim // 2\n",
        "    emb = math.log(max_timesteps) / (half_dim - 1)\n",
        "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
        "    emb = emb.to(device=timesteps.device)\n",
        "    emb = timesteps.float()[:, None] * emb[None, :]\n",
        "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
        "    if embedding_dim % 2 == 1:\n",
        "        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n",
        "    return emb\n",
        "\n",
        "\n",
        "def nonlinearity(x):\n",
        "    # swish\n",
        "    return x*torch.sigmoid(x)\n",
        "\n",
        "\n",
        "def Normalize(in_channels):\n",
        "    return torch.nn.GroupNorm(num_groups=32, num_channels=in_channels, eps=1e-6, affine=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYwkWpqZsDmt"
      },
      "source": [
        "##Transformer modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJq6Lp8w9CKW"
      },
      "source": [
        "### Building blocks of our Diffusion Model\n",
        "Attention Block and Resnet Block are used in our main model. We will use a number of Resnet blocks([(He et al., 2016](https://arxiv.org/abs/1512.03385)) followed by Attention blocks ([(Vaswani et al.,\n",
        "2017](https://arxiv.org/abs/1706.03762)) later. An example GSDM architecture for a graphical model with one observed and three latent variables. The components within the dashed lines are repeated multiple\n",
        "times. Arrows represent information flow. There are also some linear operations in the model that we do skip here."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://raw.githubusercontent.com/yasin-esfandiari/deepdiffusion_seminar/main/assets/self_attention.png' width=70% />"
      ],
      "metadata": {
        "id": "8lny0f4lbodg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "vRsg2NUr9IdA"
      },
      "outputs": [],
      "source": [
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, *, in_channels, out_channels=None, conv_shortcut=False,\n",
        "                 dropout, temb_channels=512, kernel_size=3, var_emb_channels=None):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        out_channels = in_channels if out_channels is None else out_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.use_conv_shortcut = conv_shortcut\n",
        "\n",
        "        self.norm1 = Normalize(in_channels)\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels,\n",
        "                                     out_channels,\n",
        "                                     kernel_size=kernel_size,\n",
        "                                     stride=1,\n",
        "                                     padding=kernel_size//2)\n",
        "        self.temb_proj = torch.nn.Linear(temb_channels,\n",
        "                                         out_channels)\n",
        "        if var_emb_channels is not None:\n",
        "            self.var_proj = torch.nn.Conv2d(var_emb_channels,\n",
        "                                            out_channels,\n",
        "                                            kernel_size=1)\n",
        "        self.norm2 = Normalize(out_channels)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.conv2 = torch.nn.Conv2d(out_channels,\n",
        "                                     out_channels,\n",
        "                                     kernel_size=kernel_size,\n",
        "                                     stride=1,\n",
        "                                     padding=kernel_size//2)\n",
        "        if self.in_channels != self.out_channels:\n",
        "            if self.use_conv_shortcut:\n",
        "                self.conv_shortcut = torch.nn.Conv2d(in_channels,\n",
        "                                                     out_channels,\n",
        "                                                     kernel_size=kernel_size,\n",
        "                                                     stride=1,\n",
        "                                                     padding=kernel_size//2)\n",
        "            else:\n",
        "                self.nin_shortcut = torch.nn.Conv2d(in_channels,\n",
        "                                                    out_channels,\n",
        "                                                    kernel_size=1,\n",
        "                                                    stride=1,\n",
        "                                                    padding=0)\n",
        "\n",
        "    def forward(self, x, temb, var_emb=None):\n",
        "        h = x\n",
        "        h = self.norm1(h)\n",
        "        h = nonlinearity(h)\n",
        "        h = self.conv1(h)\n",
        "\n",
        "        h = h + self.temb_proj(nonlinearity(temb))[:, :, None, None]\n",
        "        if var_emb is not None:\n",
        "            h = h + self.var_proj(var_emb)\n",
        "\n",
        "        h = self.norm2(h)\n",
        "        h = nonlinearity(h)\n",
        "        h = self.dropout(h) ## [10, 64, 840, 1]\n",
        "        h = self.conv2(h)\n",
        "\n",
        "        if self.in_channels != self.out_channels:\n",
        "            if self.use_conv_shortcut:\n",
        "                x = self.conv_shortcut(x)\n",
        "            else:\n",
        "                x = self.nin_shortcut(x)\n",
        "\n",
        "        return x+h\n",
        "\n",
        "\n",
        "class AttnBlock(nn.Module):\n",
        "    def __init__(self, in_channels, n_heads=1, attn_dim_reduce=1):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        self.norm = Normalize(in_channels)\n",
        "\n",
        "        self.q = torch.nn.Conv2d(in_channels,\n",
        "                                 in_channels//attn_dim_reduce,\n",
        "                                 kernel_size=1,\n",
        "                                 stride=1,\n",
        "                                 padding=0)\n",
        "        self.k = torch.nn.Conv2d(in_channels,\n",
        "                                 in_channels//attn_dim_reduce,\n",
        "                                 kernel_size=1,\n",
        "                                 stride=1,\n",
        "                                 padding=0)\n",
        "        self.v = torch.nn.Conv2d(in_channels,\n",
        "                                 in_channels//attn_dim_reduce,\n",
        "                                 kernel_size=1,\n",
        "                                 stride=1,\n",
        "                                 padding=0)\n",
        "        self.proj_out = torch.nn.Conv2d(in_channels//attn_dim_reduce,\n",
        "                                        in_channels,\n",
        "                                        kernel_size=1,\n",
        "                                        stride=1,\n",
        "                                        padding=0)\n",
        "\n",
        "    def sparse_forward(self, x, sparse_attention_mask_and_indices):\n",
        "        h_ = x    # [B, 64, 120, 1]\n",
        "        h_ = self.norm(h_)\n",
        "        q = self.q(h_)\n",
        "        k = self.k(h_)\n",
        "        v = self.v(h_)\n",
        "\n",
        "        b, c, h, w = q.shape\n",
        "        heads = self.n_heads\n",
        "        reshape_for_transformer = lambda t: t.reshape(b, heads, c//heads, h*w)\n",
        "        # beta = (int(c//heads)**(-0.5)) # standard attention scaling\n",
        "        # we used unnormalized attention, it should not matter\n",
        "        beta = 1\n",
        "        q = reshape_for_transformer(q)  # [B, 64, 120, 1] --> [B, 1, 64, 120]\n",
        "        k = reshape_for_transformer(k)\n",
        "        v = reshape_for_transformer(v)\n",
        "\n",
        "\n",
        "        valid_indices_mask, attendable_indices = sparse_attention_mask_and_indices\n",
        "        nq, max_attendable_keys = valid_indices_mask.shape    ## 120, 23\n",
        "        attendable_indices = attendable_indices.view(1, 1, nq, max_attendable_keys)\\\n",
        "                                               .expand(b, heads, nq, max_attendable_keys) # [B, 1, 120, 23]\n",
        "        def get_keys_or_values(t, indices):\n",
        "            *batch_shape, nd, nv = t.shape\n",
        "            t = t.transpose(-1, -2)\\\n",
        "                .view(*batch_shape, nv, 1, nd)\\\n",
        "                .expand(*batch_shape, nv, max_attendable_keys, nd)\n",
        "            index = indices.view(*batch_shape, nv, max_attendable_keys, 1)\\\n",
        "                .expand(-1, -1, -1, -1, c//heads)\n",
        "            return t.gather(dim=2, index=index)\n",
        "\n",
        "        attended_keys = get_keys_or_values(k, indices=attendable_indices)   # b x heads x h*w x max_attendable_keys x c, [B, 1, 120, 23, 64]\n",
        "        attended_values = get_keys_or_values(v, indices=attendable_indices)\n",
        "\n",
        "        weights = beta * torch.einsum('bhqkc,bhcq->bhqk', attended_keys, q) # KQ\n",
        "        inf_matrix = torch.zeros_like(valid_indices_mask)\n",
        "        inf_matrix[valid_indices_mask==0] = torch.inf                       # maskings the attention\n",
        "        weights = weights - inf_matrix.view(1, 1, nq, max_attendable_keys)  # [B, 1, 120, 23]\n",
        "        weights = weights.softmax(dim=-1)\n",
        "\n",
        "        h_ = torch.einsum('bhqk,bhqkc->bhqc', weights, attended_values)     # now multiplpy with v\n",
        "        h_ = h_.permute(0, 3, 1, 2).reshape(b, c, h, w)\n",
        "        h_ = self.proj_out(h_)\n",
        "        out = x+h_\n",
        "        return out, None\n",
        "\n",
        "    def forward(self, x, sparsity_matrix=None, sparse_attention_mask_and_indices=None, return_w=False):\n",
        "\n",
        "        if sparse_attention_mask_and_indices is not None:\n",
        "            out, w_ = self.sparse_forward(x, sparse_attention_mask_and_indices)\n",
        "            return out, w_ if return_w else out\n",
        "\n",
        "        h_ = x\n",
        "        h_ = self.norm(h_)\n",
        "        q = self.q(h_)\n",
        "        k = self.k(h_)\n",
        "        v = self.v(h_)\n",
        "\n",
        "        b, c, h, w = q.shape\n",
        "        heads = self.n_heads\n",
        "        reshape_for_transformer = lambda t: t.reshape(b, heads, c//heads, h*w)\n",
        "        q = reshape_for_transformer(q)\n",
        "        k = reshape_for_transformer(k)\n",
        "        v = reshape_for_transformer(v)\n",
        "\n",
        "        w_ = torch.einsum('bhdk,bhdq->bhqk', k, q)\n",
        "        w_ = w_ * (int(c//heads)**(-0.5))\n",
        "        if sparsity_matrix is not None:\n",
        "            inf_matrix = torch.zeros_like(sparsity_matrix)\n",
        "            inf_matrix[sparsity_matrix==0] = torch.inf\n",
        "            w_ = w_ - inf_matrix.view(-1, 1, h*w, h*w)\n",
        "        w_ = torch.nn.functional.softmax(w_, dim=3)\n",
        "        h_ = torch.einsum('bhdk,bhqk->bhdq', v, w_)\n",
        "        h_ = h_.view(b, c, h, w)\n",
        "\n",
        "        h_ = self.proj_out(h_)\n",
        "\n",
        "        out = x+h_\n",
        "        return out, w_ if return_w else out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQvvrdQQ9gfD"
      },
      "source": [
        "##Transformer Class"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define our main model that we use in the training later. One of the most important points is that we are using the idea in inpainting as follows: \"The input to Our model is a linear combination of observed and unobserved regions of the noisy image (at timestep t)\". In the following image, the observed variable is inside the medical mask while the unobserved variable is the region outside of the medical mask."
      ],
      "metadata": {
        "id": "8qZkh7AHdRN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://raw.githubusercontent.com/yasin-esfandiari/deepdiffusion_seminar/main/assets/inpainting.png' width=100% />"
      ],
      "metadata": {
        "id": "veLcDduoCqmK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our experiment, as we discussed in the beginning, the observed variable is the $u$ vector(unsorted) which we have the mask of 1, while $s$, $P$, and the intermediate variables are the unobserved variables in which the mask is 0. You can see a sketch of the input to the model while training."
      ],
      "metadata": {
        "id": "n7oFbdobA-Ak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://raw.githubusercontent.com/yasin-esfandiari/deepdiffusion_seminar/main/assets/training.png' width=100% />"
      ],
      "metadata": {
        "id": "AETBH64jBBRs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "P-DdjEE19ily"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, config, dataset, faithful_inversion_edges=None, sparse_attention_mask_and_indices=None):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dataset = dataset\n",
        "        self.n_cont = dataset.n_cont    # 20\n",
        "        self.n_discrete_options = dataset.n_discrete_options    # [2,2,2,...] list of 100 elements\n",
        "        self.shared_var_embeds = slice(0, self.n_variables)     # slice(0, 120, None)\n",
        "        self.emb_dim = self.config.model.emb_dim    # 64\n",
        "        self.temb_dim = self.emb_dim    # 64\n",
        "        self.num_transformers = config.model.num_transformers   # 6\n",
        "\n",
        "        # timestep embedding\n",
        "        self.temb = nn.Module()\n",
        "        self.temb.dense = nn.ModuleList([\n",
        "            torch.nn.Linear(self.emb_dim,\n",
        "                            self.temb_dim),\n",
        "            torch.nn.Linear(self.temb_dim,\n",
        "                            self.temb_dim),\n",
        "        ])\n",
        "\n",
        "        self.cont_in_proj = nn.Conv1d(1, self.emb_dim, kernel_size=1)\n",
        "        self.cont_out_proj = nn.Conv1d(self.emb_dim, 1, kernel_size=1)\n",
        "        disc_in_projs = {}\n",
        "        disc_out_projs = {}\n",
        "        for n_options in set(self.n_discrete_options):  ## run 1 time\n",
        "            disc_in_projs[str(n_options)] = nn.Conv1d(n_options, self.emb_dim, kernel_size=1)   ## {'2': Conv1d(2, 64, kernel_size=(1,), stride=(1,))}\n",
        "            disc_out_projs[str(n_options)] = nn.Conv1d(self.emb_dim, n_options, kernel_size=1)  ## {'2': Conv1d(64, 2, kernel_size=(1,), stride=(1,))}\n",
        "        self.disc_in_projs = nn.ModuleDict(disc_in_projs) ## ModuleDict((2): Conv1d(2, 64, kernel_size=(1,), stride=(1,)))\n",
        "        self.disc_out_projs = nn.ModuleDict(disc_out_projs) ## ModuleDict((2): Conv1d(64, 2, kernel_size=(1,), stride=(1,)))\n",
        "\n",
        "        if config.model.var_embedding:\n",
        "            self.var_embs = nn.Parameter(torch.randn(1, self.emb_dim,   ## [1, 64, 120, 1]\n",
        "                                          self.n_variables, 1),\n",
        "                              requires_grad=True)\n",
        "\n",
        "\n",
        "\n",
        "        else:\n",
        "            self.var_embs = None\n",
        "\n",
        "        # 'fixed' conditionals\n",
        "        self.cond_embs = nn.Parameter(  ## [1, 1, 64]\n",
        "            torch.randn(1, 1, self.emb_dim), requires_grad=True)\n",
        "\n",
        "        transformers = []\n",
        "        for i in range(self.num_transformers):\n",
        "            transformers.append(\n",
        "                AttnBlock(self.emb_dim, n_heads=self.config.model.n_heads,\n",
        "                          attn_dim_reduce=self.config.model.attn_dim_reduce)\n",
        "            )\n",
        "        self.transformers = nn.ModuleList(transformers)\n",
        "\n",
        "        self.res_blocks = nn.Sequential(*[ResnetBlock(in_channels=self.emb_dim, out_channels=self.emb_dim,\n",
        "                                                      temb_channels=self.temb_dim, dropout=False,\n",
        "                                                      var_emb_channels=self.emb_dim if self.config.model.var_embedding else None,\n",
        "                                                      kernel_size=1)\n",
        "                                          for _ in range(self.num_transformers)])\n",
        "\n",
        "        assert self.config.model.impose_sparsity in ['sparse', 'not']\n",
        "        if self.config.model.impose_sparsity == 'not':  ## no sparsity, just skip the initialization\n",
        "            pass\n",
        "        elif sparse_attention_mask_and_indices is None:\n",
        "            self.faithful_inversion_matrix = self.make_faithful_inversion_matrix(faithful_inversion_edges)  # [120, 120]\n",
        "            if self.config.data.save_sparsity_mask:\n",
        "                np.savez(f\"{self.config.data.dataset}_sparsity_mask.npz\",\n",
        "                         mask=self.faithful_inversion_matrix)\n",
        "            wandb.log({'attn/sparsity': wandb.Image(self.faithful_inversion_matrix.cpu().numpy())})\n",
        "            max_attendable_keys = self.faithful_inversion_matrix.sum(dim=1).max().int().item()  # 23\n",
        "            self.valid_indices_mask, self.attendable_indices = (nn.Parameter(t, requires_grad=False) for t in self.faithful_inversion_matrix.topk(k=max_attendable_keys, dim=1))  ## its better to keep the attendables (the mask is sparse)\n",
        "            # [120, 23], [120, 23]\n",
        "        else:\n",
        "            self.valid_indices_mask, self.attendable_indices = (nn.Parameter(t, requires_grad=False) for t in sparse_attention_mask_and_indices)\n",
        "\n",
        "    @property\n",
        "    def n_variables(self):\n",
        "        return self.n_cont + len(self.n_discrete_options)\n",
        "\n",
        "    @property\n",
        "    def x_dim(self):\n",
        "        return self.n_cont + sum(self.n_discrete_options)\n",
        "\n",
        "    def variable_emb_begin(self, var_index):\n",
        "        if var_index < self.n_cont:\n",
        "            return var_index\n",
        "        else:\n",
        "            return self.n_cont+sum(self.n_discrete_options[:var_index-self.n_cont])\n",
        "\n",
        "    def variable_emb_dim(self, var_index):\n",
        "        if var_index < self.n_cont:\n",
        "            return 1\n",
        "        else:\n",
        "            return self.n_discrete_options[var_index-self.n_cont]\n",
        "\n",
        "    ## these two are related\n",
        "    def project_x_to_emb(self, x, cont_in_proj, disc_in_projs):\n",
        "        B, _ = x.shape\n",
        "        NC = self.n_cont\n",
        "        if NC > 0:\n",
        "            cont = x[:, :NC].view(B, 1, NC)\n",
        "            cont_emb = cont_in_proj(cont)    # B x emb_dim x NC\n",
        "            embs = [cont_emb]\n",
        "        else:\n",
        "            embs = []\n",
        "        index = NC\n",
        "        for n_options in set(self.n_discrete_options):\n",
        "            n_var = sum(el == n_options for el in self.n_discrete_options)\n",
        "            index_step = n_var*n_options\n",
        "            values = x[:, index:index+index_step].view(B, n_var, n_options).permute(0, 2, 1)\n",
        "            emb = disc_in_projs[str(n_options)](values)    # B x emb_dim x n_var\n",
        "            embs.append(emb)\n",
        "            index += index_step\n",
        "        return torch.cat(embs, dim=2).permute(0, 2, 1) # B x n_var x emb_dim\n",
        "\n",
        "    def project_emb_to_x(self, emb):\n",
        "        B, *_ = emb.shape\n",
        "        NC = self.n_cont\n",
        "        if NC > 0:\n",
        "            cont_emb = emb[:, :NC]\n",
        "            cont_x = self.cont_out_proj(cont_emb.permute(0, 2, 1)).view(B, NC)\n",
        "            xs = [cont_x]\n",
        "        else:\n",
        "            xs = []\n",
        "        index = NC\n",
        "        for n_options in set(self.n_discrete_options):\n",
        "            n_var = sum(el == n_options for el in self.n_discrete_options)\n",
        "            emb_bit = emb[:, index:index+n_var].permute(0, 2, 1)   # B x emb_dim x n_var\n",
        "            x_bit = self.disc_out_projs[str(n_options)](emb_bit)\n",
        "            if self.config.model.softmax:\n",
        "                x_bit = torch.softmax(x_bit, dim=1)\n",
        "            x_bit = x_bit.permute(0, 2, 1)  # B x n_var x n_options\n",
        "            x_bit = x_bit.reshape(B, -1)\n",
        "            xs.append(x_bit)\n",
        "            index += n_var\n",
        "        return torch.cat(xs, dim=1)\n",
        "\n",
        "\n",
        "    def forward(self, x, t, obs_mask=None, obs=None, log_attn=False):\n",
        "        B, N = x.shape\n",
        "        NV = self.n_variables\n",
        "        D = self.emb_dim\n",
        "\n",
        "        # timestep embedding\n",
        "        temb = get_timestep_embedding(t, self.emb_dim)\n",
        "        temb = self.temb.dense[0](temb)\n",
        "        temb = nonlinearity(temb)\n",
        "        temb = self.temb.dense[1](temb)\n",
        "\n",
        "\n",
        "        if obs_mask is not None:\n",
        "            ## outside of obs_mask use the noisy image of data x\n",
        "            ## inside of obs_mask use the obs data (u vector)\n",
        "            x = x*(1-obs_mask[\"xt\"]) + obs*obs_mask[\"xt\"]                  ## [B, 220]\n",
        "\n",
        "\n",
        "        emb = self.project_x_to_emb(x, self.cont_in_proj, self.disc_in_projs)\n",
        "        assert emb.shape == (B, NV, D)\n",
        "\n",
        "        # 'fixed' conditionals\n",
        "        emb = emb + self.cond_embs * obs_mask[\"emb\"]\n",
        "\n",
        "\n",
        "        if not self.config.model.resnet:\n",
        "            emb = emb + temb.view(B, 1, D)\n",
        "        for l, (res_block, transformer) in enumerate(zip(self.res_blocks, self.transformers)):\n",
        "            emb = emb.permute(0, 2, 1).reshape(B, D, NV, 1)\n",
        "            if self.config.model.resnet:\n",
        "                var_embs = self.var_embs[:, :, self.shared_var_embeds, :] if self.var_embs is not None else None\n",
        "                emb = res_block(emb, temb, var_embs)\n",
        "\n",
        "            if self.config.model.impose_sparsity == 'not':  ## dense\n",
        "                attn_sparsity_matrix = torch.ones((B, NV, NV)).to(emb.device)\n",
        "                attn_sparsity_matrix = attn_sparsity_matrix * self.faithful_inversion_matrix.unsqueeze(0).to(emb.device)\n",
        "                emb, w = transformer(emb, return_w=True, sparsity_matrix=attn_sparsity_matrix)\n",
        "            elif self.config.model.impose_sparsity == 'sparse':\n",
        "                sparsity_things = (self.valid_indices_mask, self.attendable_indices)\n",
        "                emb, w = transformer(emb, return_w=True,\n",
        "                                     sparse_attention_mask_and_indices=sparsity_things)\n",
        "            else:\n",
        "                emb, w = transformer(emb, return_w=True)\n",
        "            emb = emb.view(B, D, NV).permute(0, 2, 1)   # [B, 64, 120, 1] --> [B, 120, 64]\n",
        "\n",
        "\n",
        "        assert emb.shape == (B, NV, D)\n",
        "        emb = self.project_emb_to_x(emb[:, :NV])    # [B, 120, 64] --> [B, 220]\n",
        "\n",
        "        assert emb.shape == (B, N)\n",
        "        if obs_mask is not None:\n",
        "            # ouside mask use the embeddings\n",
        "            # inside mask use the observation\n",
        "            emb = emb * (1 - obs_mask[\"xt\"]) + obs * obs_mask[\"xt\"]\n",
        "\n",
        "        return emb\n",
        "\n",
        "    def make_faithful_inversion_matrix(self, edges):\n",
        "        \"\"\"\n",
        "        create a attention mask based on the edges\n",
        "        \"\"\"\n",
        "        NV = self.n_variables             ## 120\n",
        "        matrix = torch.zeros((NV, NV))\n",
        "        if edges is None:\n",
        "            return matrix*0 + 1.          ## all 1\n",
        "        for i, j in edges:\n",
        "            matrix[i, j] = 1.             ## for edges\n",
        "        for i in range(NV):\n",
        "            matrix[i, i] = 1.             ## diagonal\n",
        "        return matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EMA"
      ],
      "metadata": {
        "id": "8McMPEn2buHd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plFg4yY19_Fr"
      },
      "source": [
        "Stabilizing training with Exponential Moving Average (EMA)\n",
        "\n",
        "This idea is found in most of the implementations, which allows to implement a form of model momentum. Instead of directly updating the weights of the model, we keep a copy of the previous values of the weights, and then update a weighted mean between the previous and new version of the weights. Here, we reuse the implementation proposed in the [DDIM repository](https://github.com/ermongroup/ddim)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "VW0raU0f-Bby"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(TransformerModel):\n",
        "    def reinit(self):\n",
        "        sparsity_things = (self.valid_indices_mask, self.attendable_indices) if self.config.model.impose_sparsity == 'sparse' else None\n",
        "        return TransformerModel(self.config, self.dataset, faithful_inversion_edges=None,\n",
        "                                sparse_attention_mask_and_indices=sparsity_things)\n",
        "\n",
        "\n",
        "class EMAHelper(object):\n",
        "    def __init__(self, mu=0.999):\n",
        "        self.mu = mu\n",
        "        self.shadow = {}\n",
        "\n",
        "    def register(self, module):\n",
        "        if isinstance(module, nn.DataParallel):\n",
        "            module = module.module\n",
        "        for name, param in module.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "\n",
        "    def update(self, module):\n",
        "        if isinstance(module, nn.DataParallel):\n",
        "            module = module.module\n",
        "        for name, param in module.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name].data = (\n",
        "                    1. - self.mu) * param.data + self.mu * self.shadow[name].data\n",
        "\n",
        "    def ema(self, module):\n",
        "        if isinstance(module, nn.DataParallel):\n",
        "            module = module.module\n",
        "        for name, param in module.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                param.data.copy_(self.shadow[name].data)\n",
        "\n",
        "    def ema_copy(self, module):\n",
        "        if isinstance(module, nn.DataParallel):\n",
        "            inner_module = module.module\n",
        "            module_copy = inner_module.reinit().to(inner_module.config.device)\n",
        "            module_copy.load_state_dict(inner_module.state_dict())\n",
        "            module_copy = nn.DataParallel(module_copy)\n",
        "        else:\n",
        "            module_copy = type(module)(module.config).to(module.config.device)\n",
        "            module_copy.load_state_dict(module.state_dict(), strict=False)\n",
        "\n",
        "        self.ema(module_copy)\n",
        "        return module_copy\n",
        "\n",
        "    def state_dict(self):\n",
        "        return self.shadow\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        self.shadow = state_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWWir0aQ-KH0"
      },
      "source": [
        "##Optimizer setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "FQf0skmt-MZJ"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(config, parameters):\n",
        "    if config.optim.optimizer == 'Adam':\n",
        "        return optim.Adam(parameters, lr=config.optim.lr, weight_decay=config.optim.weight_decay,\n",
        "                          betas=(config.optim.beta1, 0.999), amsgrad=config.optim.amsgrad,\n",
        "                          eps=config.optim.eps)\n",
        "    elif config.optim.optimizer == 'RMSProp':\n",
        "        return optim.RMSprop(parameters, lr=config.optim.lr, weight_decay=config.optim.weight_decay)\n",
        "    elif config.optim.optimizer == 'SGD':\n",
        "        return optim.SGD(parameters, lr=config.optim.lr, momentum=0.9)\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Optimizer {} not understood.'.format(config.optim.optimizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqMirFzv-VhA"
      },
      "source": [
        "##Diffusion Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "mfcAdeE3-fIX"
      },
      "outputs": [],
      "source": [
        "class DiffusionProcess():\n",
        "    def __init__(self, b: torch.Tensor, T):\n",
        "        \"\"\"\n",
        "        b: length T tensor of beta_1,...,beta_T\n",
        "        \"\"\"\n",
        "        assert len(b) == T\n",
        "        t = torch.arange(0, T+1).view(T+1).to(b.device)\n",
        "        self.beta = torch.cat([torch.zeros(1).to(b.device), b], dim=0)\n",
        "        self.alpha = (1 - self.beta).cumprod(dim=0).index_select(0, t).view(-1)  # this is alpha_bar in DDPM notation\n",
        "\n",
        "        at = self.alpha[:-1]\n",
        "        atp1 = self.alpha[1:]\n",
        "        btp1 = self.beta[1:]\n",
        "\n",
        "        # logvars for each x_t given x_{t+1}\n",
        "        self.reverse_p_logvar = (1 - atp1/at).log()               # the DDIM paper calls this noisy DDPM, denoted with \\hat{\\sigma}\n",
        "        self.reverse_q_logvar = (btp1 * (1-at) / (1-atp1)).log()  # from DDPM's equation 6\n",
        "\n",
        "        # such that index t corresponds to scaling of x0 (or x_{t+1}) in q(x_t|x_{t+1},x_0)\n",
        "        self.reverse_mean_x0_scaling = (at.sqrt() * btp1) / (1 - atp1)               # DDPM equation 7\n",
        "        self.reverse_mean_xtp1_scaling = (1 - btp1).sqrt() * (1 - at) / (1 - atp1)   # DDPM equation 7\n",
        "\n",
        "        # compute logvars and mean scalings such that index t corresponds to processes q(x_t|x_0)\n",
        "        self.forward_q_scaling = self.alpha.sqrt()    # DPPM equation 4\n",
        "        self.forward_q_logvar = (1-self.alpha).log()  # DPPM equation 4\n",
        "\n",
        "\n",
        "    def get(self, name, t=None, leading_dims=0, trailing_dims=0):     ## will be used in ddpm_elbo\n",
        "        attr = getattr(self, name)\n",
        "        if t is not None:\n",
        "            attr = attr.index_select(dim=0, index=t)\n",
        "        attr = attr.view(*(1,)*leading_dims, -1, *(1,)*trailing_dims)\n",
        "        return attr\n",
        "\n",
        "\n",
        "    @property\n",
        "    def elbo_weighting(self):\n",
        "        \"\"\"\n",
        "        Return weights for MSE loss (on predicted epsilon) at each time t so that optimising the loss\n",
        "        corresponds to optimising the ELBO.\n",
        "        \"\"\"\n",
        "        sigma_p = (0.5*self.reverse_p_logvar).exp()\n",
        "        w1 = (1 - self.alpha[1]) / (2*self.alpha[1]*sigma_p[0]**2)\n",
        "\n",
        "        atm1 = self.alpha[1:-1]\n",
        "        at = self.alpha[2:]\n",
        "        bt = self.beta[2:]\n",
        "        # index i of wt corresponds to loss term with x_{i+2}\n",
        "        wt = (atm1*bt**2) / (2*sigma_p[1:]**2*(1-at)*at)\n",
        "        return torch.cat([w1.view(1), wt])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX8rdZ2sBYIT"
      },
      "source": [
        "During evaluation, we will use the `ddpm_steps` function for sampling based on, and `ddpm_elbo` for logging the elbo values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "CC304sEsBgIM"
      },
      "outputs": [],
      "source": [
        "## From https://github.com/plai-group/gsdm/blob/338bff5b11e915d4bbd4292338d4d0d354eb537c/functions/denoising.py w/o any modifications\n",
        "\n",
        "\n",
        "@torch.jit.script\n",
        "def gaussian_analytical_kl(mu1, mu2, logsigma1, logsigma2):\n",
        "    return -0.5 + logsigma2 - logsigma1 + 0.5 * (logsigma1.exp() ** 2 + (mu1 - mu2) ** 2) / (logsigma2.exp() ** 2)\n",
        "\n",
        "\n",
        "@torch.jit.script\n",
        "def gaussian_log_prob(x, mu, logsigma):\n",
        "    return -logsigma - 0.5*torch.tensor(2*np.pi).log() - 0.5 * ( (x - mu) / logsigma.exp() ) ** 2\n",
        "\n",
        "#####\n",
        "\n",
        "\n",
        "def compute_alpha(beta, t, dims_like=torch.tensor([])):\n",
        "    beta = torch.cat([torch.zeros(1).to(beta.device), beta], dim=0)\n",
        "    a = (1 - beta).cumprod(dim=0).index_select(0, t + 1).view(-1)\n",
        "    while a.ndim < dims_like.ndim:\n",
        "        a = a.unsqueeze(-1)\n",
        "    return a\n",
        "\n",
        "\n",
        "def ddpm_steps(x, seq, model, b, config, obs=None, obs_mask=None):\n",
        "    with torch.no_grad():\n",
        "        n = x.size(0)\n",
        "        seq_next = [-1] + list(seq[:-1])\n",
        "        xs = [x]\n",
        "        x0_preds = []\n",
        "        betas = b\n",
        "        for i, j in zip(reversed(seq), reversed(seq_next)):\n",
        "            t = (torch.ones(n) * i).to(x.device)\n",
        "            next_t = (torch.ones(n) * j).to(x.device)\n",
        "            at = compute_alpha(betas, t.long(), x)\n",
        "            atm1 = compute_alpha(betas, next_t.long(), x)\n",
        "            beta_t = 1 - at / atm1\n",
        "            x = xs[-1].to(x.device)\n",
        "            output = model(x, t.float(), obs_mask=obs_mask, obs=obs)\n",
        "\n",
        "            if config.model.predict == 'eps':\n",
        "                x0_pred = (1.0 / at).sqrt() * x - (1.0 / at - 1).sqrt() * output\n",
        "            elif config.model.predict == 'x0':\n",
        "                x0_pred = output\n",
        "\n",
        "            x0_preds.append(x0_pred.to('cpu'))\n",
        "            mean_eps = (\n",
        "                (atm1.sqrt() * beta_t) * x0_pred + ((1 - beta_t).sqrt() * (1 - atm1)) * x\n",
        "            ) / (1.0 - at)\n",
        "\n",
        "            mean = mean_eps\n",
        "            noise = torch.randn_like(x)\n",
        "            mask = 1 - (t == 0).float()\n",
        "            mask = mask.view(-1)\n",
        "            while mask.ndim < x.ndim:\n",
        "                mask = mask.unsqueeze(-1)\n",
        "            logvar = beta_t.log()\n",
        "\n",
        "            sample = mean + mask * torch.exp(0.5 * logvar) * noise\n",
        "            xs.append(sample.to('cpu'))\n",
        "    return xs, x0_preds   ## 1001, 1000\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ddpm_elbo(model,\n",
        "              x0: torch.Tensor,\n",
        "              b: torch.Tensor, T,\n",
        "              n_cont, config,\n",
        "              obs_mask=None):\n",
        "    \"\"\"\n",
        "    b is a vector of beta_1 to beta_T\n",
        "    Indices are shifted relative to paper. We sum the:\n",
        "    - likelihood for x_{-1} given x_0\n",
        "    - KLs for each x_{t-1} given x_t for t in [1, T-2] inclusive\n",
        "    - KL between Gaussian and x_{T-1}\n",
        "    \"\"\"\n",
        "    device = b.device\n",
        "    process = DiffusionProcess(b, T)\n",
        "    obs_mask_dict = {'xt': None, 'emb': None} if obs_mask is None else obs_mask\n",
        "    def apply_mask(x, mask, slice_mask_to=None, slice_mask_from=None):\n",
        "        if mask is None:\n",
        "            return x\n",
        "        if slice_mask_to is not None:\n",
        "            mask = mask[:, :slice_mask_to]\n",
        "        if slice_mask_from is not None:\n",
        "            mask = mask[:, slice_mask_from:]\n",
        "        return x * (1-mask.unsqueeze(1))\n",
        "\n",
        "    B, *data_dims = x0.shape\n",
        "    x0 = x0.view(B, 1, *data_dims).to(device)       ## [B, 1, 220]\n",
        "    kwargs = dict(leading_dims=1, trailing_dims=len(data_dims))\n",
        "\n",
        "    # compute various factors and sample xt -----------------------------------------------\n",
        "    forward_scaling = process.get('forward_q_scaling', **kwargs)\n",
        "    forward_logvar = process.get('forward_q_logvar', **kwargs)\n",
        "    scaling_p1, logvar_p1 = forward_scaling[:, 1:], forward_logvar[:, 1:]   # q(x_t|x0) for t=1,...,T\n",
        "    xtp1s = scaling_p1 * x0 + (0.5*logvar_p1).exp() * torch.randn(size=(B, T, *data_dims), device=device)\n",
        "    tp1s = torch.arange(1, T+1).view(1, T).expand(B, T).to(device)\n",
        "    output = []\n",
        "    for i in range(T): # tp1, xtp1 in zip(tp1s, xtp1s):\n",
        "        output.append(model(xtp1s[:, i], tp1s[:, i], obs=x0[:, 0], obs_mask=obs_mask))\n",
        "    # stack again\n",
        "    output = torch.stack(output, dim=1)\n",
        "    assert output.shape == (B, T, *data_dims)\n",
        "    if config.model.predict == 'eps':\n",
        "        x0_from_tp1 = (1./scaling_p1) * (xtp1s - output*(0.5*logvar_p1).exp())\n",
        "    elif config.model.predict == 'x0':\n",
        "        x0_from_tp1 = output\n",
        "\n",
        "    # means for predicted x_0,...,x_{T-1}\n",
        "    reverse_mean_x0_scaling = process.get('reverse_mean_x0_scaling', **kwargs)\n",
        "    reverse_mean_xtp1_scaling = process.get('reverse_mean_xtp1_scaling', **kwargs)\n",
        "    p_mean = x0_from_tp1 * reverse_mean_x0_scaling + xtp1s * reverse_mean_xtp1_scaling\n",
        "    q_mean = x0 * reverse_mean_x0_scaling + xtp1s * reverse_mean_xtp1_scaling\n",
        "    p_logvar = process.get('reverse_p_logvar', **kwargs)\n",
        "    q_logvar = process.get('reverse_q_logvar', **kwargs)\n",
        "\n",
        "    # evaluate sum of KL losses for predicting x_1,...,x_{T-1}\n",
        "    kls = gaussian_analytical_kl(mu1=q_mean[:, 1:], mu2=p_mean[:, 1:],\n",
        "                                 logsigma1=0.5*q_logvar[:, 1:], logsigma2=0.5*p_logvar[:, 1:])\n",
        "    assert kls.shape == (B, T-1, *data_dims)\n",
        "    kl_sum = apply_mask(kls, obs_mask_dict[\"xt\"]).flatten(start_dim=1).sum(dim=1)\n",
        "\n",
        "    # evaluate likelihood for x0\n",
        "    assert len(data_dims) == 1\n",
        "    D = data_dims[0]\n",
        "    likelihood = gaussian_log_prob(x=x0[:, :, :n_cont], mu=p_mean[:, :1, :n_cont], logsigma=0.5*p_logvar[:, :1, :n_cont])\n",
        "    likelihood = apply_mask(likelihood, obs_mask_dict[\"xt\"], slice_mask_to=n_cont).flatten(start_dim=1).sum(dim=1)\n",
        "    x0_onehot = x0[:, :, n_cont:]\n",
        "    x0_probs = p_mean[:, :1, n_cont:]\n",
        "    disc_likelihood = apply_mask(x0_onehot * x0_probs.log().clamp(min=-1e10), obs_mask_dict[\"xt\"], slice_mask_from=n_cont).flatten(start_dim=1).sum(dim=1)\n",
        "    likelihood = likelihood + disc_likelihood\n",
        "    # likelihood for discrete variables\n",
        "\n",
        "    # compute KL at T\n",
        "    q_mean = forward_scaling[:, -1:] * x0\n",
        "    q_logvar = forward_logvar[:, -1:]\n",
        "    p_mean = torch.zeros_like(q_mean)\n",
        "    p_logvar = torch.zeros_like(q_logvar)\n",
        "    kl_T = gaussian_analytical_kl(mu1=q_mean, mu2=p_mean, logsigma1=0.5*q_logvar, logsigma2=0.5*p_logvar)\n",
        "    kl_T = apply_mask(kl_T, obs_mask_dict[\"xt\"]).flatten(start_dim=1).sum(dim=1)\n",
        "\n",
        "    elbo = likelihood - kl_sum - kl_T\n",
        "    return {'elbo': elbo.mean().item(), 'likelihood': likelihood.mean().item(), 'kl_sum': kl_sum.mean().item(), 'kl_T': kl_T.mean().item(), 'disc_likelihood': disc_likelihood.mean().item()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need a variance schedule for our diffusion process. We can set the beta values given $\\beta_{start}$ and $\\beta_{end}$ quadratically, linearly, etc."
      ],
      "metadata": {
        "id": "dEKbZ_Xv67N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_beta_schedule(beta_schedule, *, beta_start, beta_end, num_diffusion_timesteps):\n",
        "    \"\"\"\n",
        "    Returns the beta values as a numpy array based on the given schedule, the range, and number of timesteps\n",
        "    \"\"\"\n",
        "\n",
        "    def sigmoid(x):\n",
        "        return 1 / (np.exp(-x) + 1)\n",
        "\n",
        "    if beta_schedule == \"quad\":\n",
        "        betas = (\n",
        "            np.linspace(\n",
        "                beta_start ** 0.5,\n",
        "                beta_end ** 0.5,\n",
        "                num_diffusion_timesteps,\n",
        "                dtype=np.float64,\n",
        "            )\n",
        "            ** 2\n",
        "        )\n",
        "    elif beta_schedule == \"linear\":\n",
        "        betas = np.linspace(\n",
        "            beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64\n",
        "        )\n",
        "    elif beta_schedule == \"const\":\n",
        "        betas = beta_end * np.ones(num_diffusion_timesteps, dtype=np.float64)\n",
        "    elif beta_schedule == \"jsd\":  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
        "        betas = 1.0 / np.linspace(\n",
        "            num_diffusion_timesteps, 1, num_diffusion_timesteps, dtype=np.float64\n",
        "        )\n",
        "    elif beta_schedule == \"sigmoid\":\n",
        "        betas = np.linspace(-6, 6, num_diffusion_timesteps)\n",
        "        betas = sigmoid(betas) * (beta_end - beta_start) + beta_start\n",
        "    else:\n",
        "        raise NotImplementedError(beta_schedule)\n",
        "    assert betas.shape == (num_diffusion_timesteps,)\n",
        "    return betas"
      ],
      "metadata": {
        "id": "u93jlOAW62Nx"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45UCgyGi_EzP"
      },
      "source": [
        "##Loss computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "OHjVLMeu_Gr4"
      },
      "outputs": [],
      "source": [
        "def noise_estimation_loss(model,\n",
        "                        x0: torch.Tensor,\n",
        "                        t: torch.LongTensor,\n",
        "                        e: torch.Tensor,\n",
        "                        b: torch.Tensor,\n",
        "                        w: torch.Tensor,\n",
        "                        predict,\n",
        "                        obs_mask,\n",
        "                        log_attn=False,\n",
        "                        mean_over_latents=False):\n",
        "    a = (1-b).cumprod(dim=0).index_select(0, t)\n",
        "    while a.ndim < x0.ndim:\n",
        "        a = a.unsqueeze(-1)\n",
        "    x = x0 * a.sqrt() + e * (1.0 - a).sqrt()\n",
        "\n",
        "\n",
        "    kwargs = {}\n",
        "    ## fixed conditional\n",
        "    kwargs = {**kwargs, 'obs_mask': obs_mask, 'obs': obs_mask[\"xt\"]*x0}\n",
        "\n",
        "    # obs_mask a dictionary: elements of 0 or 1\n",
        "    #   ['emb']: [B, 120, 1]\n",
        "    #   ['xt']:  [B, 220] same shape as x --> as conditional\n",
        "    # obs   [B, 220]  keep the unsorted part as 1 (observed data)\n",
        "\n",
        "    output = model(x, t.float(), log_attn=log_attn, **kwargs)   # [B, 220]\n",
        "\n",
        "    target = {'eps': e, 'x0': x0}[predict]  # [B, 220]\n",
        "    loss_per_item = (target - output).square()\n",
        "\n",
        "    if mean_over_latents:\n",
        "        loss_per_item = loss_per_item.flatten(start_dim=1).mean(dim=1)  # [8]\n",
        "    else:\n",
        "        loss_per_item = loss_per_item.flatten(start_dim=1).sum(dim=1)\n",
        "    if w is not None:\n",
        "        loss_per_item = loss_per_item * w.index_select(0, t) * len(t)   #\n",
        "\n",
        "    return loss_per_item.mean(dim=0)    # [1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference / Sampling\n",
        "\n",
        "Here we have the blocks corresponding to Inference. The sampling procedure is given below in a sketch.\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/yasin-esfandiari/deepdiffusion_seminar/main/assets/sampling.png' width=100% />"
      ],
      "metadata": {
        "id": "3AhNZ1bsIQUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we add other member classes to our TransformerModel class. These will be used in our sampling.\n",
        "\n",
        "Function `sample_xT` samples a batch of images(pure noise) from Gaussian distribution (the latest noise level)\n",
        "\n",
        "Function `dequantize` converts the discrete values to a continuous one. In our experiment, it makes the matrix $P$ as continuous.\n",
        "\n",
        "Function `requantize` converts the continuous values to a discrete one. In our experiment, it discretizes the matrix $P$.\n",
        "\n",
        "Function `sample` given model and data, it uses the ddpm sampler.\n"
      ],
      "metadata": {
        "id": "crGd0FqJ0QdC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "mvzYlD9JCds4"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(TransformerModel):\n",
        "    def sample_xT(self, B):\n",
        "        device = next(self.parameters()).device\n",
        "        return torch.randn((B, self.x_dim), device=device)                  ## the most noisy\n",
        "\n",
        "    def dequantize(self, x):\n",
        "        ## https://github.com/plai-group/gsdm/blob/338bff5b11e915d4bbd4292338d4d0d354eb537c/models/diffusion.py#L530\n",
        "        \"\"\"\n",
        "        refer to section 3.5 Handling Mixed Continuous/Discrete Variables in GSDM paper\n",
        "        \"\"\"\n",
        "        x_cont, x_disc = x                                                  ##[B, 20], [B, 100]\n",
        "\n",
        "        B, cont_dim = x_cont.shape\n",
        "        assert x_disc.shape == (B, len(self.n_discrete_options))\n",
        "\n",
        "        # log_prob = torch.zeros(B)\n",
        "        dequants = []\n",
        "        for dim, n_options in enumerate(self.n_discrete_options):\n",
        "            val = x_disc[:, dim]\n",
        "            dequants.append(TF.one_hot(val, num_classes=n_options).float())\n",
        "        if len(dequants) == 0:\n",
        "            dequants = torch.zeros((B, 0))\n",
        "        else:\n",
        "            dequants = torch.cat(dequants, dim=1)                           ##[B, 200]\n",
        "\n",
        "        return torch.cat([x_cont, dequants], dim=1)#, log_prob               ##[B, 20+200]\n",
        "\n",
        "    def requantize(self, x):\n",
        "        ## https://github.com/plai-group/gsdm/blob/338bff5b11e915d4bbd4292338d4d0d354eb537c/models/diffusion.py#L548\n",
        "        \"\"\"\n",
        "        refer to section 3.5 Handling Mixed Continuous/Discrete Variables in GSDM paper\n",
        "        \"\"\"\n",
        "        n_discrete_options = self.n_discrete_options                        # [2, ..., 2]\n",
        "        n_discrete_dims = sum(n_discrete_options)                           ## 200\n",
        "        if n_discrete_dims == 0:\n",
        "            return x, torch.zeros((x.shape[0], 0))\n",
        "        x_cont, x_dequant = x[:, :-n_discrete_dims], x[:, -n_discrete_dims:]  ## [B, 20], [B, 200]\n",
        "\n",
        "        B, cont_dim = x_cont.shape\n",
        "        assert x_dequant.shape == (B, n_discrete_dims)\n",
        "\n",
        "        x_disc = []\n",
        "        for i, n_options in enumerate(n_discrete_options):\n",
        "            start, end = sum(n_discrete_options[:i]), sum(n_discrete_options[:i+1])\n",
        "            dequant_chunk = x_dequant[:, start:end]\n",
        "            x_disc.append(torch.argmax(dequant_chunk, dim=1))\n",
        "        x_disc = torch.stack(x_disc, dim=1)\n",
        "\n",
        "        return x_cont, x_disc                                                 ## [B, 20], [B, 100]\n",
        "\n",
        "class Diffusion(object):\n",
        "    def __init__(self, args, config, device=None):\n",
        "        self.args = args\n",
        "        self.config = config\n",
        "\n",
        "        assert config.training.batch_size >= config.sampling.sampling_batch_size\n",
        "\n",
        "        if device is None:\n",
        "            device = (\n",
        "                torch.device(\"cuda\")\n",
        "                if torch.cuda.is_available()\n",
        "                else torch.device(\"cpu\")\n",
        "            )\n",
        "        self.device = device\n",
        "\n",
        "        self.model_var_type = config.model.var_type\n",
        "        betas = get_beta_schedule(\n",
        "            beta_schedule=config.diffusion.beta_schedule,\n",
        "            beta_start=config.diffusion.beta_start,\n",
        "            beta_end=config.diffusion.beta_end,\n",
        "            num_diffusion_timesteps=config.diffusion.num_diffusion_timesteps,\n",
        "        ) ## [0.0001, ...., 0.005]\n",
        "        betas = self.betas = torch.from_numpy(betas).float().to(self.device)\n",
        "        self.num_timesteps = betas.shape[0]\n",
        "\n",
        "        alphas = 1.0 - betas\n",
        "        alphas_cumprod = alphas.cumprod(dim=0)\n",
        "        alphas_cumprod_prev = torch.cat(\n",
        "            [torch.ones(1).to(device), alphas_cumprod[:-1]], dim=0\n",
        "        )\n",
        "        posterior_variance = (\n",
        "            betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
        "        )\n",
        "        if self.model_var_type == \"fixedlarge\":\n",
        "            self.logvar = betas.log()\n",
        "        elif self.model_var_type == \"fixedsmall\":\n",
        "            self.logvar = posterior_variance.clamp(min=1e-20).log()\n",
        "\n",
        "    def sample(self, x, model, obs=None, obs_mask=None, last=True):\n",
        "        try:\n",
        "            skip = self.args.skip\n",
        "        except Exception:\n",
        "            skip = 1\n",
        "\n",
        "\n",
        "        if self.args.sample_type == \"ddpm\":\n",
        "            if self.args.skip_type == \"uniform\":\n",
        "                skip = self.num_timesteps // self.args.timesteps\n",
        "                seq = range(0, self.num_timesteps, skip)\n",
        "            elif self.args.skip_type == \"quad\":\n",
        "                seq = (\n",
        "                    np.linspace(\n",
        "                        0, np.sqrt(self.num_timesteps * 0.8), self.args.timesteps\n",
        "                    )\n",
        "                    ** 2\n",
        "                )\n",
        "                seq = [int(s) for s in list(seq)]\n",
        "            else:\n",
        "                raise NotImplementedError\n",
        "            # from functions.denoising import ddpm_steps   --> defined previously\n",
        "\n",
        "            x = ddpm_steps(x, seq, model, self.betas, config=self.config,\n",
        "                           obs=obs, obs_mask=obs_mask)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        if last:\n",
        "            x = x[0][-1]  ## xs is list acess with 0 and pick the last image\n",
        "        return x\n",
        "\n",
        "    def log_samples(self, model, batch, obs_mask, prefix=''):\n",
        "        gt_cont, gt_disc = batch[0], batch[1]\n",
        "        data = model.module.dequantize(batch[:2])[0].to(self.device)\n",
        "        xT = model.module.sample_xT(self.config.sampling.sampling_batch_size)                         ## sample the xT from gaussian\n",
        "        samples = self.sample(xT, model, obs=data, obs_mask=obs_mask)\n",
        "        samples_cont, samples_disc = model.module.requantize(samples)\n",
        "\n",
        "        dataset_metrics = self.dataset.validation_metrics(samples_disc, samples_cont, gt_cont=gt_cont, gt_disc=gt_disc, model=model)\n",
        "\n",
        "        dataset_metrics = {f'samples{prefix}/{k}': v for k, v in dataset_metrics.items()}\n",
        "        wandb.log(dataset_metrics, commit=False)\n",
        "        fig, ax = self.dataset.plot(samples_cont, samples_disc, obs_mask=obs_mask)\n",
        "        if fig is not None:\n",
        "            wandb.log({f'samples{prefix}': wandb.Image(fig)}, commit=False)\n",
        "\n",
        "\n",
        "    def log_elbos(self, model, data_batch, obs_mask, prefix=''):\n",
        "        n_cont = data_batch[0].shape[1]\n",
        "        x0 = model.module.dequantize(data_batch[:2])\n",
        "        elbos = ddpm_elbo(model, x0=x0, b=self.betas, T=self.num_timesteps, n_cont=n_cont,\n",
        "                          obs_mask=obs_mask, config=self.config)\n",
        "        elbos['quantized_elbo'] = elbos['elbo']\n",
        "        elbos = {prefix+'/'+k: v for k, v in elbos.items()}\n",
        "        wandb.log(elbos, commit=False)\n",
        "\n",
        "\n",
        "\n",
        "    def validate(self, model, ema_helper, iteration):\n",
        "        vis_start = time.time()\n",
        "        # draw samples -----------------------------------\n",
        "        model.eval()\n",
        "        if self.config.model.ema:\n",
        "            valid_model = ema_helper.ema_copy(model)\n",
        "        else:\n",
        "            valid_model = model\n",
        "        valid_model.eval()\n",
        "\n",
        "\n",
        "        batch_size = self.config.sampling.sampling_batch_size\n",
        "        obs_mask = self.dataset.sample_obs_mask(batch_size, self.device)\n",
        "\n",
        "\n",
        "        sampling_start_time = time.time()\n",
        "        self.log_samples(valid_model, self.valid_batch, obs_mask=obs_mask, prefix='ema')\n",
        "        sampling_time = time.time() - sampling_start_time\n",
        "\n",
        "        # compute ELBO -----------------------------------\n",
        "        elbo_mask = self.dataset.sample_obs_mask(self.config.sampling.sampling_batch_size, self.device)\n",
        "        self.log_elbos(valid_model, self.valid_batch, elbo_mask, prefix='valid-ema')\n",
        "        self.log_elbos(model, self.valid_batch, elbo_mask, prefix='valid')\n",
        "        # reset state dict -------------------------------\n",
        "        model.train()\n",
        "        del valid_model\n",
        "        wandb.log({'vis_time': time.time()-vis_start,\n",
        "                   \"sampling_time\": sampling_time,\n",
        "                   \"iteration\": iteration}, commit=False)\n",
        "        wandb.log({})\n",
        "\n",
        "\n",
        "    def load_ckpt(self, eval_path, dataset):\n",
        "        model = TransformerModel(self.config, dataset,\n",
        "                                 dataset.faithful_inversion_edges())\n",
        "        states = torch.load(\n",
        "            self.args.eval_path,\n",
        "            map_location=self.config.device,\n",
        "        )\n",
        "        model = model.to(self.device)\n",
        "        model = torch.nn.DataParallel(model)\n",
        "        # remove temporary internal parameters that have mismatching shape\n",
        "        if self.config.model.impose_sparsity != 'not':\n",
        "            del states[0][\"module.valid_indices_mask\"]\n",
        "            del states[0][\"module.attendable_indices\"]\n",
        "            valid_indices_mask = model.module.valid_indices_mask\n",
        "            attendable_indices = model.module.attendable_indices\n",
        "\n",
        "            del model.module.valid_indices_mask\n",
        "            del model.module.attendable_indices\n",
        "\n",
        "        model.load_state_dict(states[0], strict=False)\n",
        "        if self.config.model.ema:\n",
        "            ema_helper = EMAHelper(mu=self.config.model.ema_rate)\n",
        "            ema_helper.register(model)\n",
        "            ema_helper.load_state_dict(states[-1])\n",
        "            ema_helper.ema(model)\n",
        "            if self.config.model.impose_sparsity != 'not':\n",
        "                ema_helper.valid_indices_mask = valid_indices_mask\n",
        "                ema_helper.attendable_indices = attendable_indices\n",
        "        else:\n",
        "            ema_helper = None\n",
        "\n",
        "        # reattach mask\n",
        "        if self.config.model.impose_sparsity != 'not':\n",
        "            model.module.valid_indices_mask = valid_indices_mask\n",
        "            model.module.attendable_indices = attendable_indices\n",
        "        return model, ema_helper\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.dataset, self.test_dataset = get_dataset(self.args, self.config)\n",
        "        model, ema_helper = self.load_ckpt(self.args.eval_path, self.dataset)\n",
        "        loader = torch.utils.data.DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.config.sampling.sampling_batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=self.config.data.num_workers,\n",
        "        )\n",
        "        self.valid_batch = next(iter(loader))\n",
        "\n",
        "        self.validate(model, ema_helper, iteration=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "CNxvXvoAcjzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Diffusion(Diffusion):\n",
        "    def train(self):\n",
        "        args, config = self.args, self.config\n",
        "        dataset, test_dataset = get_dataset(args, config)\n",
        "\n",
        "        self.dataset = dataset\n",
        "\n",
        "        train_loader = data.DataLoader(\n",
        "            dataset,\n",
        "            batch_size=config.training.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=config.data.num_workers,\n",
        "        )\n",
        "\n",
        "        valid_loader = data.DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=config.sampling.sampling_batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=config.data.num_workers,\n",
        "        )\n",
        "        self.valid_batch = next(iter(valid_loader))\n",
        "\n",
        "\n",
        "        wandb.log({'optimal_log_prob': dataset.avg_log_prob()})\n",
        "\n",
        "        model = TransformerModel(config, dataset,\n",
        "                                 dataset.faithful_inversion_edges())    # a set of edges\n",
        "        print('Parameters:', sum(p.numel() for p in model.parameters()))\n",
        "        print('Trainable parameters:', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "        for name, module in model.named_children():\n",
        "            print(name, sum(p.numel() for p in module.parameters())/1e6, 'million')\n",
        "\n",
        "\n",
        "        model = model.to(self.device)\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "        optimizer = get_optimizer(self.config, model.parameters())\n",
        "\n",
        "        if self.config.model.ema:\n",
        "            ema_helper = EMAHelper(mu=self.config.model.ema_rate)\n",
        "            ema_helper.register(model)\n",
        "        else:\n",
        "            ema_helper = None\n",
        "\n",
        "        start_epoch, step = 0, 0\n",
        "        if self.args.weight_loss:\n",
        "            loss_weights = DiffusionProcess(self.betas, self.num_timesteps).elbo_weighting  ## [1000] weighting of Diffusion loss for each timestep\n",
        "            wandb.log({'log_loss_weights': wandb.Histogram(loss_weights.cpu().log())})\n",
        "        else:\n",
        "            loss_weights = None\n",
        "\n",
        "\n",
        "        for epoch in range(start_epoch, self.args.n_epochs):\n",
        "            epoch_start = time.time()\n",
        "            data_start = time.time()\n",
        "            data_time = 0\n",
        "            repeating_train_loader = itertools.cycle(train_loader)\n",
        "\n",
        "\n",
        "            for i, batch in zip(range(config.training.max_epoch_iters), repeating_train_loader):\n",
        "\n",
        "                data_time += time.time() - data_start\n",
        "                model.train()\n",
        "                step += 1\n",
        "\n",
        "                x = model.module.dequantize(batch[0:2])   # [B, 220], [B]\n",
        "\n",
        "                n = x.size(0)                               ## [B]\n",
        "                x = x.to(self.device)\n",
        "                e = torch.randn_like(x)                     ## [B, 220] same shape as x\n",
        "                b = self.betas  ## [1000]\n",
        "\n",
        "                # antithetic sampling\n",
        "                t = torch.randint(\n",
        "                    low=0, high=self.num_timesteps, size=(n // 2 + 1,)\n",
        "                ).to(self.device)                           ## tensor([ 13, 317,  65, 234, 862,  66, 595, 264, 603]\n",
        "                t = torch.cat([t, self.num_timesteps - t - 1], dim=0)[:n]   ## [B] [ 13, 317,  65, 234, 862,  66, 595, 264, 603, 986, 682, 934, 765, 137, 933, 404]\n",
        "                obs_mask = dataset.sample_obs_mask(len(x), self.device)\n",
        "\n",
        "\n",
        "                loss = mse_loss = noise_estimation_loss(model, x, t, e, b, w=loss_weights,\n",
        "                                                            predict=self.config.model.predict,\n",
        "                                                            obs_mask=obs_mask,\n",
        "                                                            log_attn=False,\n",
        "                                                            mean_over_latents=config.training.mean_latents_loss)\n",
        "\n",
        "\n",
        "                logging.info(\n",
        "                    f\"step: {step}, loss: {loss.item()}, data time: {data_time / (i+1)}\"\n",
        "                )\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "\n",
        "                try:\n",
        "                    grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "                        model.parameters(), config.optim.grad_clip\n",
        "                    )\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                if self.config.model.ema:\n",
        "                    ema_helper.update(model)\n",
        "\n",
        "                if i % self.args.log_freq == 0:\n",
        "                    wandb.log({'loss': loss, 'epoch': epoch, 'iter': i,\n",
        "                                'grad_norm': grad_norm})\n",
        "\n",
        "\n",
        "                if step % self.config.training.snapshot_freq == 0 or step == 1:\n",
        "                    states = [\n",
        "                        model.state_dict(),\n",
        "                        optimizer.state_dict(),\n",
        "                        epoch,\n",
        "                        step,\n",
        "                    ]\n",
        "                    if self.config.model.ema:\n",
        "                        states.append(ema_helper.state_dict())\n",
        "\n",
        "                    torch.save(\n",
        "                        states,\n",
        "                        os.path.join(self.args.log_path, \"ckpt_{}.pth\".format(step)),\n",
        "                    )\n",
        "                    torch.save(states, os.path.join(self.args.log_path, \"ckpt.pth\"))\n",
        "\n",
        "                data_start = time.time()\n",
        "\n",
        "            wandb.log({'epoch_time': time.time()-epoch_start})\n",
        "            self.validate(model=model, ema_helper=ema_helper, iteration=step)\n"
      ],
      "metadata": {
        "id": "Edlkt_4icgML"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghL8HaTVVZ8_"
      },
      "source": [
        "#Runner Instance\n",
        "Create a runner instance from our diffusion model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "A-P0f-B7VbDx"
      },
      "outputs": [],
      "source": [
        "runner = Diffusion(args, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "GpSbzsqNHwmD"
      },
      "outputs": [],
      "source": [
        "def set_log_path(args, config):\n",
        "    train = args.eval_path is None\n",
        "    if train:\n",
        "        args.log_path = os.path.join(args.exp, \"logs\", wandb.run.id)\n",
        "        if os.path.exists(args.log_path):\n",
        "            print(\"overwrite the existing folder\")\n",
        "            shutil.rmtree(args.log_path)\n",
        "            os.makedirs(args.log_path)\n",
        "        else:\n",
        "          os.makedirs(args.log_path)\n",
        "\n",
        "        with open(os.path.join(args.log_path, \"config.yml\"), \"w\") as f:\n",
        "            yaml.dump(config, f, default_flow_style=False)\n",
        "\n",
        "        # setup logger\n",
        "        level = getattr(logging, args.verbose.upper(), None)\n",
        "\n",
        "        if not isinstance(level, int):\n",
        "            raise ValueError(\"level {} not supported\".format(args.verbose))\n",
        "\n",
        "        handler1 = logging.StreamHandler()\n",
        "        handler2 = logging.FileHandler(os.path.join(args.log_path, \"stdout.txt\"))\n",
        "        formatter = logging.Formatter(\n",
        "            \"%(levelname)s - %(filename)s - %(asctime)s - %(message)s\"\n",
        "        )\n",
        "        handler1.setFormatter(formatter)\n",
        "        handler2.setFormatter(formatter)\n",
        "        logger = logging.getLogger()\n",
        "        logger.addHandler(handler1)\n",
        "        logger.addHandler(handler2)\n",
        "        logger.setLevel(level)\n",
        "\n",
        "    else:\n",
        "        level = getattr(logging, args.verbose.upper(), None)\n",
        "        if not isinstance(level, int):\n",
        "            raise ValueError(\"level {} not supported\".format(args.verbose))\n",
        "\n",
        "        handler1 = logging.StreamHandler()\n",
        "        formatter = logging.Formatter(\n",
        "            \"%(levelname)s - %(filename)s - %(asctime)s - %(message)s\"\n",
        "        )\n",
        "        handler1.setFormatter(formatter)\n",
        "        logger = logging.getLogger()\n",
        "        logger.addHandler(handler1)\n",
        "        logger.setLevel(level)\n",
        "\n",
        "set_log_path(args, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH1uF3pxUDKj"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "NZ_i6FbBGFFZ"
      },
      "outputs": [],
      "source": [
        "if args.eval_path is None:\n",
        "    logging.info(\"Writing log file to {}\".format(args.log_path))\n",
        "    logging.info(\"Exp instance id = {}\".format(os.getpid()))\n",
        "\n",
        "    runner.train()\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1gxOahm52xD"
      },
      "source": [
        "##Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We do evaluation during training by default. In case you want to use the available checkpoints to evaluate, run the code from the beginning and set the path to checkpoint. Uncomment the following\n",
        "eval_path = 'sorting_experiments/logs/gsdm'\n",
        "\n",
        "You should make another runner instance from the Diffusion Model."
      ],
      "metadata": {
        "id": "ogrCmO_B-D9X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "uo9DR1F24VzX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903,
          "referenced_widgets": [
            "a283c91f0b96456c93d003e3a9615c7b",
            "766c5035cd4444f28dffff8c8d2561ab",
            "da6fa49c178c4f6a8fd8f3bde0bc7c75",
            "9383707d553b4efdb2174d649625a762",
            "22d035d6ff9c4e4291c50e23bd1976a8",
            "47fb4d037d11433588fc7c06b5fc73a6",
            "25a67895207643d2958c7f4861e88e1f",
            "a6b71569cb0a48a8b23bfcfdfe632ae9"
          ]
        },
        "outputId": "34e33fc0-c74a-44cd-97e6-0286db2a26cf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.024 MB of 0.024 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a283c91f0b96456c93d003e3a9615c7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁</td></tr><tr><td>samplesema/rmse</td><td>▁</td></tr><tr><td>samplesema/sort_completed</td><td>▁</td></tr><tr><td>samplesema/sort_matches</td><td>▁</td></tr><tr><td>sampling_time</td><td>▁</td></tr><tr><td>valid-ema/disc_likelihood</td><td>▁</td></tr><tr><td>valid-ema/elbo</td><td>▁</td></tr><tr><td>valid-ema/kl_T</td><td>▁</td></tr><tr><td>valid-ema/kl_sum</td><td>▁</td></tr><tr><td>valid-ema/likelihood</td><td>▁</td></tr><tr><td>valid-ema/quantized_elbo</td><td>▁</td></tr><tr><td>valid/disc_likelihood</td><td>▁</td></tr><tr><td>valid/elbo</td><td>▁</td></tr><tr><td>valid/kl_T</td><td>▁</td></tr><tr><td>valid/kl_sum</td><td>▁</td></tr><tr><td>valid/likelihood</td><td>▁</td></tr><tr><td>valid/quantized_elbo</td><td>▁</td></tr><tr><td>vis_time</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>0</td></tr><tr><td>samplesema/rmse</td><td>0.0</td></tr><tr><td>samplesema/sort_completed</td><td>True</td></tr><tr><td>samplesema/sort_matches</td><td>1.0</td></tr><tr><td>sampling_time</td><td>21.56427</td></tr><tr><td>valid-ema/disc_likelihood</td><td>-0.0166</td></tr><tr><td>valid-ema/elbo</td><td>273.83307</td></tr><tr><td>valid-ema/kl_T</td><td>5.10408</td></tr><tr><td>valid-ema/kl_sum</td><td>98.2395</td></tr><tr><td>valid-ema/likelihood</td><td>377.17667</td></tr><tr><td>valid-ema/quantized_elbo</td><td>273.83307</td></tr><tr><td>valid/disc_likelihood</td><td>-0.0166</td></tr><tr><td>valid/elbo</td><td>273.87631</td></tr><tr><td>valid/kl_T</td><td>5.10408</td></tr><tr><td>valid/kl_sum</td><td>98.27199</td></tr><tr><td>valid/likelihood</td><td>377.25238</td></tr><tr><td>valid/quantized_elbo</td><td>273.87631</td></tr><tr><td>vis_time</td><td>45.87583</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gsdm_codessz2</strong> at: <a href='https://wandb.ai/yasin_esf/GSDM/runs/gsdm_codessz2' target=\"_blank\">https://wandb.ai/yasin_esf/GSDM/runs/gsdm_codessz2</a><br/>Synced 4 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240323_225938-gsdm_codessz2/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "if args.eval_path is not None:\n",
        "    runner.evaluate()\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion (Summary)\n",
        "\n",
        "In this notebook we looked over the Sorting problem via the lens of graphically structured diffusion models. If you re-check the plot for training (the video after the definition of the `plot` function), we can see as the steps increase, our approximated sorted vector will become close to the ground-truth sorted vector, thus less red blocks. In the evaluated checkpoint, we see no red blocks that means we do not have any mismatches."
      ],
      "metadata": {
        "id": "33BBojoCnfs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "\n",
        "[1] https://github.com/plai-group/gsdm\n",
        "\n",
        "[2] https://github.com/acids-ircam/diffusion_models/blob/main/diffusion_03_waveform.ipynb\n",
        "\n",
        "[3] https://www.youtube.com/watch?v=TQZcT6-r68A​"
      ],
      "metadata": {
        "id": "bh4kuUPD5_r1"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a283c91f0b96456c93d003e3a9615c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_766c5035cd4444f28dffff8c8d2561ab",
              "IPY_MODEL_da6fa49c178c4f6a8fd8f3bde0bc7c75"
            ],
            "layout": "IPY_MODEL_9383707d553b4efdb2174d649625a762"
          }
        },
        "766c5035cd4444f28dffff8c8d2561ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22d035d6ff9c4e4291c50e23bd1976a8",
            "placeholder": "​",
            "style": "IPY_MODEL_47fb4d037d11433588fc7c06b5fc73a6",
            "value": "0.024 MB of 0.024 MB uploaded\r"
          }
        },
        "da6fa49c178c4f6a8fd8f3bde0bc7c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25a67895207643d2958c7f4861e88e1f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6b71569cb0a48a8b23bfcfdfe632ae9",
            "value": 1
          }
        },
        "9383707d553b4efdb2174d649625a762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22d035d6ff9c4e4291c50e23bd1976a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47fb4d037d11433588fc7c06b5fc73a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25a67895207643d2958c7f4861e88e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6b71569cb0a48a8b23bfcfdfe632ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}